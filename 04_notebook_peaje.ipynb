{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829ecfe7",
   "metadata": {},
   "source": [
    "# 1. Combinar archivos \n",
    "#### Archivo de enrgia extraida con archivo de empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5f21255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Iniciando procesamiento de archivos...\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0123.xlsx ‚Üí ./pre_data/peaje_agentes_0123.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0124.xlsx ‚Üí ./pre_data/peaje_agentes_0124.xlsx\n",
      "  ‚ö†Ô∏è 3 centrales sin EMPRESA: ['Yapacani' 'Chimor√©' 'Sucre - Aranjuez']\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0125.xlsx ‚Üí ./pre_data/peaje_agentes_0125.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0223.xlsx ‚Üí ./pre_data/peaje_agentes_0223.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0224.xlsx ‚Üí ./pre_data/peaje_agentes_0224.xlsx\n",
      "  ‚ö†Ô∏è 3 centrales sin EMPRESA: ['Yapacani' 'Chimor√©' 'Sucre - Aranjuez']\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0225.xlsx ‚Üí ./pre_data/peaje_agentes_0225.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0323.xlsx ‚Üí ./pre_data/peaje_agentes_0323.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0324.xlsx ‚Üí ./pre_data/peaje_agentes_0324.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0325.xlsx ‚Üí ./pre_data/peaje_agentes_0325.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0423.xlsx ‚Üí ./pre_data/peaje_agentes_0423.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0424.xlsx ‚Üí ./pre_data/peaje_agentes_0424.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0425.xlsx ‚Üí ./pre_data/peaje_agentes_0425.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0523.xlsx ‚Üí ./pre_data/peaje_agentes_0523.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0524.xlsx ‚Üí ./pre_data/peaje_agentes_0524.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0525.xlsx ‚Üí ./pre_data/peaje_agentes_0525.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0623.xlsx ‚Üí ./pre_data/peaje_agentes_0623.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0624.xlsx ‚Üí ./pre_data/peaje_agentes_0624.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0625.xlsx ‚Üí ./pre_data/peaje_agentes_0625.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0723.xlsx ‚Üí ./pre_data/peaje_agentes_0723.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0724.xlsx ‚Üí ./pre_data/peaje_agentes_0724.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0823.xlsx ‚Üí ./pre_data/peaje_agentes_0823.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0824.xlsx ‚Üí ./pre_data/peaje_agentes_0824.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0923.xlsx ‚Üí ./pre_data/peaje_agentes_0923.xlsx\n",
      "  ‚ö†Ô∏è 3 centrales sin EMPRESA: ['Yapacani' 'Chimor√©' 'Sucre - Aranjuez']\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_0924.xlsx ‚Üí ./pre_data/peaje_agentes_0924.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_1023.xlsx ‚Üí ./pre_data/peaje_agentes_1023.xlsx\n",
      "  ‚ö†Ô∏è 3 centrales sin EMPRESA: ['Yapacani' 'Chimor√©' 'Sucre - Aranjuez']\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_1024.xlsx ‚Üí ./pre_data/peaje_agentes_1024.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_1123.xlsx ‚Üí ./pre_data/peaje_agentes_1123.xlsx\n",
      "  ‚ö†Ô∏è 3 centrales sin EMPRESA: ['Yapacani' 'Chimor√©' 'Sucre - Aranjuez']\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_1124.xlsx ‚Üí ./pre_data/peaje_agentes_1124.xlsx\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_1223.xlsx ‚Üí ./pre_data/peaje_agentes_1223.xlsx\n",
      "  ‚ö†Ô∏è 3 centrales sin EMPRESA: ['Yapacani' 'Chimor√©' 'Sucre - Aranjuez']\n",
      "[OK] ./downloads\\extracted_peaje_c_ret_1224.xlsx ‚Üí ./pre_data/peaje_agentes_1224.xlsx\n",
      "‚úÖ Proceso completado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIGURACI√ìN ===\n",
    "CENTRALES_FILE = './data/empresas_distribuidoras.xlsx'\n",
    "INPUT_PATTERN = './downloads/extracted_peaje_c_ret_*.xlsx'\n",
    "OUTPUT_PREFIX = './pre_data/peaje_agentes_'\n",
    "\n",
    "# === FUNCIONES AUXILIARES ===\n",
    "\n",
    "def detectar_fila_encabezado(df):\n",
    "    for i, row in df.iterrows():\n",
    "        if any(str(cell).strip().upper() == \"AGENTE\" for cell in row):\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "def normalizar_nombre(nombre, nombres_centrales, alias):\n",
    "    x = str(nombre).strip()\n",
    "    if x in alias:\n",
    "        return alias[x]\n",
    "    \n",
    "    # Limpieza m√°s profunda para coincidencias flexibles\n",
    "    x_clean = re.sub(r'\\W+', '', x).upper()\n",
    "    \n",
    "    for k in nombres_centrales:\n",
    "        k_clean = re.sub(r'\\W+', '', k).upper()\n",
    "        if k_clean == x_clean:\n",
    "            return k\n",
    "    \n",
    "    # Casos especiales para Agua√≠\n",
    "    if \"AGUAI\" in x_clean or \"AGUA√ç\" in x_clean:\n",
    "        if \"AUTOPRODUCTOR\" in x_clean:\n",
    "            return \"Aguai (Autoproductor)\"\n",
    "        return \"Agua√≠ Energia\"\n",
    "    \n",
    "    return x\n",
    "\n",
    "# === MAPA DE ALIAS DE CENTRALES ===\n",
    "alias = {\n",
    "    \"Kanata en Arocagua\": \"Kanata ARO\",\n",
    "    \"Kanata en Valle Hermoso\": \"Kanata VHE\",\n",
    "    \"Misicuni en Arocagua\": \"Misicuni ARO\",\n",
    "    \"Misicuni en Valle Hermoso\": \"Misicuni VHE\",\n",
    "    \"Yunchara\": \"Yunchara\",\n",
    "    \"Agua√≠ Energ√≠a\": \"Agua√≠ Energia\",\n",
    "    \"AGUA√ç ENERG√çA S.A.\": \"Agua√≠ Energia\",\n",
    "    \"Santa Cruz (Agua√≠)\": \"Santa Cruz (Agua√≠)\",\n",
    "    \"R√çO EL√âCTRICO S.A.\": \"RIO ELECTRICO S.A.\",\n",
    "    \"CHACO ENERG√çAS S.A.\": \"CHACO ENERGIAS S.A.\",\n",
    "    \"RIOELEC S.A.\": \"RIO ELECTRICO S.A.\",\n",
    "}\n",
    "\n",
    "# === MAPA EXHAUSTIVO DE AGENTES A EMPRESAS ===\n",
    "mapeo_agente_empresa = {\n",
    "    # CRE\n",
    "    \"Guaracachi\": \"CRE\",\n",
    "    \"Urub√≥\": \"CRE\",\n",
    "    \"Urub√≥ 115 kV\": \"CRE\",\n",
    "    \"Urub√≥ 115\": \"CRE\",\n",
    "    \"Arboleda\": \"CRE\",\n",
    "    \"Warnes\": \"CRE\",\n",
    "    \"Brechas\": \"CRE\",\n",
    "    \"Brechas 69\": \"CRE\",\n",
    "    \"Brechas 115\": \"CRE\",\n",
    "    \"Troncos\": \"CRE\",\n",
    "    \"Troncos 115\": \"CRE\",\n",
    "    \"Troncos - Las Misiones\": \"CRE\",\n",
    "    \"Troncos 115 (Las Misiones)\": \"CRE\",\n",
    "    \"Yapacan√≠\": \"CRE\",\n",
    "    \"B√©lgica\": \"CRE\",\n",
    "    \"San Juli√°n\": \"CRE\",\n",
    "    \"Camiri - Cordillera\": \"CRE\",\n",
    "    \"Guarayos\": \"CRE\",\n",
    "    \n",
    "    # DELAPAZ\n",
    "    \"Kenko\": \"DELAPAZ\",\n",
    "    \"Cumbre\": \"DELAPAZ\",\n",
    "    \"Chuspipata\": \"DELAPAZ\",\n",
    "    \"Caranavi\": \"DELAPAZ\",\n",
    "    \"San Buenaventura\": \"DELAPAZ\",\n",
    "    \"Palca\": \"DELAPAZ\",\n",
    "    \"Contorno Bajo\": \"DELAPAZ\",\n",
    "    \"Choquetanga\": \"DELAPAZ\",\n",
    "    \n",
    "    # ELFEC\n",
    "    \"Arocagua\": \"ELFEC\",\n",
    "    \"Valle Hermoso\": \"ELFEC\",\n",
    "    \"Irpa Irpa\": \"ELFEC\",\n",
    "    \"Chimore\": \"ELFEC\",\n",
    "    \"San Jos√©\": \"ELFEC\",\n",
    "    \"Paracaya\": \"ELFEC\",\n",
    "    \"Carrasco\": \"ELFEC\",\n",
    "    \"Qollpana\": \"ELFEC\",\n",
    "    \"Villa Tunari\": \"ELFEC\",\n",
    "    \"Santiva√±ez\": \"ELFEC\",\n",
    "    \n",
    "    # ENDE DEORURO\n",
    "    \"Vinto\": \"ENDE DEORURO S.A.\",\n",
    "    \"Vinto 115\": \"ENDE DEORURO S.A.\",\n",
    "    \"Catavi\": \"ENDE DEORURO S.A.\",\n",
    "    \"Jeruyo\": \"ENDE DEORURO S.A.\",\n",
    "    \"Lucianita\": \"ENDE DEORURO S.A.\",\n",
    "    \"Catavi 115\": \"ENDE DEORURO S.A.\",\n",
    "    \"Pagador\": \"ENDE DEORURO S.A.\",\n",
    "    \n",
    "    # SEPSA\n",
    "    \"Sacaca\": \"SEPSA\",\n",
    "    \"Ocuri\": \"SEPSA\",\n",
    "    \"Potos√≠\": \"SEPSA\",\n",
    "    \"Potos√≠ 115\": \"SEPSA\",\n",
    "    \"Potosi 69\": \"SEPSA\",\n",
    "    \"Potosi 115\": \"SEPSA\",\n",
    "    \"Punutuma\": \"SEPSA\",\n",
    "    \"Don Diego\": \"SEPSA\",\n",
    "    \"CM  Karachipampa\": \"SEPSA\",\n",
    "    \"Litio - Lipez\": \"SEPSA\",\n",
    "    \"Litio 115 kV\": \"SEPSA\",\n",
    "    \"Torre Huayco\": \"SEPSA\",\n",
    "    \"Portugalete\": \"SEPSA\",\n",
    "    \"Chilcobija\": \"SEPSA\",\n",
    "    \"Telamayu\": \"SEPSA\",\n",
    "    \"La Plata\": \"SEPSA\",\n",
    "    \"ECEBOL Potos√≠\": \"SEPSA\",\n",
    "    \n",
    "    # CESSA\n",
    "    \"Mariaca\": \"CESSA\",\n",
    "    \"Sucre\": \"CESSA\",\n",
    "    \"Sucre - Fancesa\": \"CESSA\",\n",
    "    \"Sucre 115\": \"CESSA\",\n",
    "    \n",
    "    # ENDE\n",
    "    \"Tazna\": \"ENDE\",\n",
    "    \"Uyuni\": \"ENDE\",\n",
    "    \"Uyuni - Uyuni\": \"ENDE\",\n",
    "    \"Las Carreras\": \"ENDE\",\n",
    "    \n",
    "    # SETAR\n",
    "    \"Tarija\": \"SETAR\",\n",
    "    \"Villamontes\": \"SETAR\",\n",
    "    \"Yacuiba\": \"SETAR\",\n",
    "    \"Bermejo\": \"SETAR\",\n",
    "    \n",
    "    # ENDE DELBENI\n",
    "    \"Yucumo\": \"ENDE DELBENI S.A.M.\",\n",
    "    \"San Borja\": \"ENDE DELBENI S.A.M.\",\n",
    "    \"San Ignacio de Moxos\": \"ENDE DELBENI S.A.M.\",\n",
    "    \"Trinidad\": \"ENDE DELBENI S.A.M.\",\n",
    "    \"Para√≠so\": \"ENDE DELBENI S.A.M.\",\n",
    "    \n",
    "    # NO REGULADOS\n",
    "    \"EMDEECRUZ\": \"NO REGULADOS\",\n",
    "    \"EMVINTO - COMIBOL\": \"NO REGULADOS\",\n",
    "    \"COBOCE\": \"NO REGULADOS\",\n",
    "    \"MINERA SAN CRISTOBAL S.A.\": \"NO REGULADOS\",\n",
    "    \"YLB (Contrato ENDE)\": \"NO REGULADOS\",\n",
    "    \"LAS LOMAS\": \"NO REGULADOS\",\n",
    "    \"CERAMICA GUADALQUIVIR\": \"NO REGULADOS\",\n",
    "    \"EMPACAR S.A.\": \"NO REGULADOS\",\n",
    "    \n",
    "    # AGUA√ç\n",
    "    \"Agua√≠ Energia\": \"AGUA√ç ENERG√çA S.A.\",\n",
    "    \"Aguai (Autoproductor)\": \"AGUA√ç ENERG√çA S.A.\"\n",
    "}\n",
    "\n",
    "# === PROCESAMIENTO DE ARCHIVOS ===\n",
    "\n",
    "def procesar_archivos():\n",
    "    try:\n",
    "        df_centrales = pd.read_excel(CENTRALES_FILE)\n",
    "        df_centrales['AGENTE'] = df_centrales['AGENTE'].astype(str).str.strip()\n",
    "\n",
    "        if not {'AGENTE', \"EMPRESA\"}.issubset(df_centrales.columns):\n",
    "            print(\"Error: El archivo debe contener columnas 'AGENTE', y 'EMPRESA'\")\n",
    "            return\n",
    "\n",
    "        mapeo_generadores = dict(zip(df_centrales['AGENTE'], df_centrales['EMPRESA']))\n",
    "        nombres_centrales = set(df_centrales['AGENTE'])\n",
    "\n",
    "        # Combinar mapeos\n",
    "        mapeo_completo = {**mapeo_generadores, **mapeo_agente_empresa}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar archivo de mapeo {CENTRALES_FILE}: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    for input_file in glob.glob(INPUT_PATTERN):\n",
    "        file_number = re.search(r'extracted_peaje_c_ret_(\\d+)\\.xlsx', input_file)\n",
    "\n",
    "        if not file_number:\n",
    "            continue\n",
    "\n",
    "        file_number = file_number.group(1)\n",
    "        output_file = f\"{OUTPUT_PREFIX}{file_number}.xlsx\"\n",
    "\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"[Omitido] {output_file} ya existe.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            df_raw = pd.read_excel(input_file, header=None)\n",
    "            start_row = detectar_fila_encabezado(df_raw)\n",
    "            df = pd.read_excel(input_file, skiprows=start_row)\n",
    "            df.columns = [str(col).strip() for col in df.columns]\n",
    "            \n",
    "            # Manejar columnas duplicadas\n",
    "            if df.columns.duplicated().any():\n",
    "                df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "\n",
    "            central_col = next((c for c in df.columns if 'central' in c.lower() or 'agente' in c.lower()), None)\n",
    "            if central_col and central_col != 'AGENTE':\n",
    "                df = df.rename(columns={central_col: 'AGENTE'})\n",
    "            if 'AGENTE' not in df.columns:\n",
    "                print(f\"[Error] No se encontr√≥ columna 'AGENTE' en {input_file}\")\n",
    "                continue\n",
    "\n",
    "            df['AGENTE'] = df['AGENTE'].astype(str).str.strip()\n",
    "\n",
    "            # Eliminaci√≥n de filas basura\n",
    "            pattern_basura = r'TOTAL|TOTALES|Nota|Tipo de cambio|nan|CARGOS POR INYECCIONES|TOTAL\\s*-\\s*AGUAI'\n",
    "            df = df[~df['AGENTE'].str.contains(pattern_basura, case=False, na=True, regex=True)]\n",
    "            df = df[~df['AGENTE'].str.match(r'^\\d{4}-\\d{2}-\\d{2}', na=False)]\n",
    "            df = df[~df['AGENTE'].str.upper().str.contains(r'AGENTE\\s*ENERGIA|POTENCIA', na=False)]\n",
    "            df = df[df['AGENTE'].notna() & (df['AGENTE'] != '')]\n",
    "\n",
    "            # Identificaci√≥n de filas v√°lidas\n",
    "            df['AGENTE_CLEAN'] = df['AGENTE'].str.strip().str.upper()\n",
    "            centrales_validas = set(x.upper() for x in nombres_centrales)\n",
    "            first_valid_idx = df[df['AGENTE_CLEAN'].isin(centrales_validas)].index.min()\n",
    "            if pd.isna(first_valid_idx):\n",
    "                print(f\"[Error] No se encontraron centrales v√°lidas en {input_file}\")\n",
    "                continue\n",
    "            df = df.loc[first_valid_idx:].copy()\n",
    "\n",
    "            # Normalizaci√≥n\n",
    "            df['AGENTE_NORMALIZADA'] = df['AGENTE'].apply(\n",
    "                lambda x: normalizar_nombre(x, nombres_centrales, alias)\n",
    "            )\n",
    "            \n",
    "            # CORRECCI√ìN PRINCIPAL: Asignaci√≥n completa de empresas\n",
    "            df['EMPRESA'] = df['AGENTE_NORMALIZADA'].map(mapeo_completo)\n",
    "            \n",
    "            # Forzar presencia de ambas centrales Agua√≠\n",
    "            aguai_centrales = [\"Agua√≠ Energia\", \"Aguai (Autoproductor)\"]\n",
    "            for central in aguai_centrales:\n",
    "                if central not in df['AGENTE_NORMALIZADA'].values:\n",
    "                    nueva_fila = {'AGENTE_NORMALIZADA': central, 'EMPRESA': \"AGUA√ç ENERG√çA S.A.\"}\n",
    "                    for col in df.columns:\n",
    "                        if 'kW' in col or 'kWh' in col or 'USD' in col:\n",
    "                            nueva_fila[col] = 0.0\n",
    "                    df = pd.concat([df, pd.DataFrame([nueva_fila])], ignore_index=True)\n",
    "\n",
    "            # Procesamiento num√©rico\n",
    "            for col in df.columns:\n",
    "                if 'kW' in col or 'kWh' in col or 'USD' in col:\n",
    "                    df[col] = (\n",
    "                        df[col]\n",
    "                        .astype(str)\n",
    "                        .str.replace(',', '')\n",
    "                        .str.replace(' ', '')\n",
    "                        .replace('nan', None)\n",
    "                        .astype(float)\n",
    "                    )\n",
    "\n",
    "            # Manejo de columnas de peaje\n",
    "            peaje_cols = [col for col in df.columns if 'Peaje' in col and 'USD' in col]\n",
    "            columnas_conservar = ['AGENTE_NORMALIZADA', 'EMPRESA'] + peaje_cols\n",
    "            df_final = df[columnas_conservar].copy()\n",
    "            df_final = df_final.rename(columns={'AGENTE_NORMALIZADA': 'AGENTE'})\n",
    "\n",
    "            # Renombrar columnas espec√≠ficas\n",
    "            rename_columns = {\n",
    "                'Energ√≠a': 'Energ√≠a kWh',\n",
    "                'Potencia Firme Remunerada': 'Potencia kW'\n",
    "            }\n",
    "            df_final = df_final.rename(columns=rename_columns)\n",
    "\n",
    "            # Guardar resultados\n",
    "            df_final.to_excel(output_file, index=False)\n",
    "            print(f\"[OK] {input_file} ‚Üí {output_file}\")\n",
    "\n",
    "            # Detectar centrales sin mapeo\n",
    "            faltantes = df_final[df_final['EMPRESA'].isna()]['AGENTE'].unique()\n",
    "            if len(faltantes) > 0:\n",
    "                print(f\"  ‚ö†Ô∏è {len(faltantes)} centrales sin EMPRESA: {faltantes[:3]}{'...' if len(faltantes) > 3 else ''}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {input_file}: {str(e)}\")\n",
    "            try:\n",
    "                Path('./errors').mkdir(exist_ok=True)\n",
    "                df.to_excel(f\"./errors/ERROR_{file_number}.xlsx\", index=False)\n",
    "            except Exception as inner_e:\n",
    "                print(f\"Error al guardar archivo de error: {inner_e}\")\n",
    "\n",
    "# === EJECUCI√ìN PRINCIPAL ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üîÑ Iniciando procesamiento de archivos...\")\n",
    "    procesar_archivos()\n",
    "    print(\"‚úÖ Proceso completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af1003e",
   "metadata": {},
   "source": [
    "# 2. Merge archivos energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98c74589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidaci√≥n completada en formato largo.\n",
      "Filas totales: 9316\n",
      "Archivo guardado como 'serie_peaje_filiales.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "def consolidar_en_formato_largo():\n",
    "    archivos = sorted(glob.glob('./pre_data/peaje_agentes_*.xlsx'))\n",
    "    if not archivos:\n",
    "        print(\"No se encontraron archivos.\")\n",
    "        return\n",
    "\n",
    "    registros = []\n",
    "\n",
    "    for archivo in archivos:\n",
    "        try:\n",
    "            # Extraer mes y a√±o del nombre del archivo\n",
    "            periodo = archivo.split('_')[-1].split('.')[0]\n",
    "            mes = int(periodo[:2])\n",
    "            a√±o = 2000 + int(periodo[2:])\n",
    "            fecha = datetime(a√±o, mes, 1)\n",
    "\n",
    "            df = pd.read_excel(archivo)\n",
    "\n",
    "            # Verificar columnas esenciales\n",
    "            if 'AGENTE' not in df.columns:\n",
    "                print(f\"Omitido: {archivo} no tiene columna AGENTE.\")\n",
    "                continue\n",
    "\n",
    "            columnas_necesarias = ['AGENTE', 'EMPRESA']\n",
    "            columnas_datos = [col for col in df.columns if col not in columnas_necesarias]\n",
    "            \n",
    "            # Si no hay columnas de datos, omitir\n",
    "            if not columnas_datos:\n",
    "                print(f\"Omitido: {archivo} no tiene columnas de datos.\")\n",
    "                continue\n",
    "\n",
    "            # Si no existe columna TECNOLOGIA, crear una con NaN\n",
    "            if 'TECNOLOGIA' not in df.columns:\n",
    "                df['TECNOLOGIA'] = None\n",
    "\n",
    "            # Derretir (melt) el DataFrame para convertir a formato largo\n",
    "            temp = pd.melt(\n",
    "                df,\n",
    "                id_vars=['AGENTE', 'EMPRESA'],\n",
    "                value_vars=columnas_datos,\n",
    "                var_name='VARIABLE',\n",
    "                value_name='VALOR'\n",
    "            )\n",
    "            \n",
    "            temp['FECHA'] = fecha\n",
    "            registros.append(temp)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {archivo}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not registros:\n",
    "        print(\"No se pudo consolidar ning√∫n archivo v√°lido.\")\n",
    "        return\n",
    "\n",
    "    df_largo = pd.concat(registros, ignore_index=True)\n",
    "    df_largo = df_largo[['FECHA', \"AGENTE\" , 'EMPRESA', 'VARIABLE', 'VALOR']]\n",
    "\n",
    "    df_largo.to_excel(\"./preprocess/serie_peaje_filiales.xlsx\", index=False)\n",
    "    print(\"Consolidaci√≥n completada en formato largo.\")\n",
    "    print(f\"Filas totales: {len(df_largo)}\")\n",
    "    print(\"Archivo guardado como 'serie_peaje_filiales.xlsx'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    consolidar_en_formato_largo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcaea20",
   "metadata": {},
   "source": [
    "# 3. Creacion de serie de tiempo de energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d927312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo guardado como 'serie_peaje_filiales_2.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar archivo en formato largo\n",
    "df = pd.read_excel(\"./preprocess/serie_peaje_filiales.xlsx\")\n",
    "\n",
    "# Asegurar que FECHA sea tipo datetime\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'])\n",
    "\n",
    "# Formatear fecha como MMYYYY (ejemplo: 012023)\n",
    "df['PERIODO'] = df['FECHA'].dt.strftime(\"%m%Y\")\n",
    "\n",
    "# Crear columna combinada: VARIABLE + PERIODO\n",
    "df['COLUMNA'] = df['VARIABLE'] + ' ' + df['PERIODO']\n",
    "\n",
    "# Pivotear: una fila por CENTRAL, GENERADOR, TECNOLOG√çA\n",
    "tabla_pivot = df.pivot_table(\n",
    "    index=['AGENTE', 'EMPRESA'],\n",
    "    columns='COLUMNA',\n",
    "    values='VALOR',\n",
    "    aggfunc='sum'  # En caso de duplicados, los suma\n",
    ")\n",
    "\n",
    "# Resetear √≠ndice para que sea un DataFrame plano\n",
    "tabla_pivot = tabla_pivot.reset_index()\n",
    "\n",
    "# --- NUEVO C√ìDIGO PARA ORDENAR COLUMNAS CRONOL√ìGICAMENTE ---\n",
    "# 1. Separar las columnas en componentes\n",
    "fixed_cols = ['AGENTE', 'EMPRESA']\n",
    "other_cols = [c for c in tabla_pivot.columns if c not in fixed_cols]\n",
    "\n",
    "# 2. Crear DataFrame temporal para ordenaci√≥n\n",
    "cols_df = pd.DataFrame({\n",
    "    'col_name': other_cols,\n",
    "    'variable': [c.split()[0] for c in other_cols],  # Ej: 'Energ√≠a MWh'\n",
    "    'periodo': [c.split()[-1] for c in other_cols]   # Ej: '012023'\n",
    "})\n",
    "\n",
    "# 3. Convertir periodo a fecha para ordenar correctamente\n",
    "cols_df['fecha'] = pd.to_datetime(cols_df['periodo'], format='%m%Y')\n",
    "\n",
    "# 4. Ordenar por: 1. Tipo de variable, 2. Fecha cronol√≥gica\n",
    "cols_df = cols_df.sort_values(by=['variable', 'fecha'])\n",
    "\n",
    "# 5. Construir lista final de columnas ordenadas\n",
    "ordered_columns = fixed_cols + cols_df['col_name'].tolist()\n",
    "\n",
    "# 6. Aplicar nuevo orden al DataFrame\n",
    "tabla_pivot = tabla_pivot[ordered_columns]\n",
    "# --- FIN DEL NUEVO C√ìDIGO ---\n",
    "\n",
    "# Guardar resultado\n",
    "tabla_pivot.to_excel(\"./preprocess/serie_peaje_filiales_2.xlsx\", index=False)\n",
    "print(\"‚úÖ Archivo guardado como 'serie_peaje_filiales_2.xlsx'\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c7cfd",
   "metadata": {},
   "source": [
    "# 4. Depuracion de serie de tiempo de peaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63a9a865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo generado con columna 'Peaje generaci√≥n USD/MWh' en orden cronol√≥gico.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar archivo original\n",
    "df = pd.read_excel(\"./preprocess/serie_peaje_filiales_2.xlsx\")\n",
    "\n",
    "# Columnas fijas\n",
    "fixed_cols = ['AGENTE', 'EMPRESA']\n",
    "\n",
    "# Identificar columnas de peaje por mes\n",
    "peaje_cols = [col for col in df.columns if 'Peaje' in col and any(x in col for x in ['ENDE Trans.', 'ENDE USD', 'ISA', 'TESA', 'filiales'])]\n",
    "\n",
    "# Obtener lista de fechas √∫nicas (ej. 012023, 022023, etc.)\n",
    "fechas = sorted(set(col.split()[-1] for col in peaje_cols))\n",
    "\n",
    "# Crear diccionario con sumas por mes\n",
    "peaje_generacion = pd.DataFrame(df[fixed_cols])\n",
    "\n",
    "for fecha in fechas:\n",
    "    columnas_mes = [col for col in peaje_cols if col.endswith(fecha)]\n",
    "    peaje_generacion[f'Peaje generaci√≥n USD/MWh {fecha}'] = df[columnas_mes].sum(axis=1)\n",
    "\n",
    "# Ordenar columnas cronol√≥gicamente (despu√©s de las fijas)\n",
    "cols_ordenadas = fixed_cols + sorted([col for col in peaje_generacion.columns if col.startswith('Peaje generaci√≥n')], key=lambda x: pd.to_datetime(x.split()[-1], format='%m%Y'))\n",
    "peaje_generacion = peaje_generacion[cols_ordenadas]\n",
    "\n",
    "# Guardar archivo final\n",
    "peaje_generacion.to_excel(\"./data/serie_peaje.xlsx\", index=False)\n",
    "print(\"‚úÖ Archivo generado con columna 'Peaje generaci√≥n USD/MWh' en orden cronol√≥gico.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
